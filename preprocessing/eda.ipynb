{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/welddb_cleaned.csv')\n",
    "data.info()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Samples')\n",
    "plt.title('Missing Values in the Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 4 main scenarios to handle missing values:\n",
    "# - we have all the target values, except Charpy impact toughness\n",
    "# - we have Charpy impact toughness,\n",
    "# - we have all the target values\n",
    "# - other cases (ie for example 2 target values)\n",
    "\n",
    "target_labels = ['Yield strength / MPa', \n",
    "                 'Ultimate tensile strength / MPa', \n",
    "                 'Elongation / %', \n",
    "                 'Reduction of Area / %', \n",
    "                 'Charpy impact toughness / J']\n",
    "\n",
    "scenarios = {\n",
    "    'all_targets': target_labels,\n",
    "    'all_targets_except_charpy': target_labels[:-1],\n",
    "    'charpy_only': target_labels[-1],\n",
    "    'other': []\n",
    "}\n",
    "\n",
    "target_df = data[target_labels]\n",
    "target_df.fillna(np.nan, inplace=True)\n",
    "print(target_df.head())\n",
    "\n",
    "scenarios_count = {}\n",
    "for s in scenarios.keys():\n",
    "    scenarios_count[s] = 0\n",
    "\n",
    "for i, row in target_df.iterrows():\n",
    "    missing_values = row.isnull().sum()\n",
    "    \n",
    "    if missing_values == 0:\n",
    "        scenarios_count['all_targets'] += 1\n",
    "    elif missing_values == 1 and pd.isna(row['Charpy impact toughness / J']):\n",
    "        scenarios_count['all_targets_except_charpy'] += 1\n",
    "    elif missing_values == 4 and not pd.isna(row['Charpy impact toughness / J']):\n",
    "        scenarios_count['charpy_only'] += 1\n",
    "    else:\n",
    "        scenarios_count['other'] += 1\n",
    "\n",
    "print(scenarios_count)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(scenarios_count.values(), labels=scenarios_count.keys(), autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Data Distribution by Scenario')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative = data.select_dtypes(include=['int64', 'float64'])\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(quantitative.corr(), cmap='viridis', annot=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of missing values for each feature\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "missing_values = missing_values.sort_values(ascending=False)\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering pour vérifier l'éventuelle présence de groupes aux caractéristiques similaires dans le dataset\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# drop target values\n",
    "features = data.drop(target_labels, axis=1)\n",
    "features.fillna(0, inplace=True)\n",
    "\n",
    "# pca\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_pca)\n",
    "\n",
    "# we check optimal number of clusters\n",
    "inertia = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "    kmeans.fit(features_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n",
    "\n",
    "# 3 seems to be the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(features_scaled)\n",
    "clusters = kmeans.predict(features_scaled)\n",
    "\n",
    "# viz\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(features_pca[:, 0], features_pca[:, 1], features_pca[:, 2], c=clusters, cmap='viridis')\n",
    "ax.set_xlabel('PCA 1')\n",
    "ax.set_ylabel('PCA 2')\n",
    "ax.set_zlabel('PCA 3')\n",
    "plt.title('Clusters')\n",
    "plt.show()\n",
    "\n",
    "# distribution des 6 targets pour chaque cluster\n",
    "target_df['Cluster'] = clusters\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, target in enumerate(target_labels):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.countplot(x='Cluster', data=target_df, hue=target)\n",
    "    plt.title(target)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddifférence de distribution dans les clusters\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, target in enumerate(target_labels):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    temp_df = target_df[[target, 'Cluster']].dropna()\n",
    "    sns.histplot(temp_df, x=target, hue='Cluster', multiple='stack', palette='viridis', kde=False)\n",
    "    plt.title(f'Distribution of {target}')\n",
    "    plt.xlabel(target)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
